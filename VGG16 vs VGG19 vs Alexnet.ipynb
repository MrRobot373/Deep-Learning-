{"cells":[{"cell_type":"markdown","source":["#VGG 16"],"metadata":{"id":"TVVYRa293c2L"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import (\n","    Dense,\n","    Conv2D,\n","    MaxPool2D,\n","    Flatten,\n","    Dropout,\n","    BatchNormalization,\n",")\n","base_model = keras.applications.VGG16(\n","    weights='imagenet',\n","    input_shape=(128, 128, 3),\n","    include_top=False)\n","base_model.summary()\n","base_model.trainable = False"],"metadata":{"id":"Bp_xZlMsspvN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inputs = keras.Input(shape=(128, 128, 3))\n","x = base_model(inputs, training=False)\n","x = keras.layers.GlobalAveragePooling2D()(x)\n","outputs = outputs = keras.layers.Dense(1)(x)\n","model = keras.Model(inputs, outputs)\n","model.summary()"],"metadata":{"id":"gOtF1epWyMeO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=True), metrics=[keras.metrics.BinaryAccuracy()])\n","datagen_train = ImageDataGenerator(\n","    samplewise_center=True,  # set each sample mean to 0\n","    rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n","    zoom_range=0.1,  # Randomly zoom image\n","    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n","    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n","    horizontal_flip=True,  # randomly flip images\n","    vertical_flip=False,\n","    validation_split=0.2\n",")\n","batch_size = 8\n","train_it = datagen_train.flow_from_directory(\n","    \"/content/drive/MyDrive/Kirmizi_Pistachio/Pistachio_Image_Dataset\",\n","    target_size=(128, 128),\n","    color_mode=\"rgb\",\n","    class_mode=\"binary\",\n","    batch_size=batch_size,\n","    subset='training'\n",")\n","valid_it = datagen_train.flow_from_directory(\n","    \"/content/drive/MyDrive/Kirmizi_Pistachio/Pistachio_Image_Dataset\",\n","    target_size=(128, 128),\n","    color_mode=\"rgb\",\n","    class_mode=\"binary\",\n","    batch_size=batch_size,\n","    subset='validation'\n",")\n","model.fit(train_it, steps_per_epoch=train_it.samples/batch_size, validation_data=valid_it, validation_steps=valid_it.samples/batch_size, epochs=20)\n","base_model.trainable = True"],"metadata":{"id":"sci961wKxXKz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(optimizer=keras.optimizers.RMSprop(learning_rate = .00001),  # Very low learning rate\n","              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n","              metrics=[keras.metrics.BinaryAccuracy()])\n","\n","model.fit(train_it, steps_per_epoch=train_it.samples/batch_size, validation_data=valid_it, validation_steps=valid_it.samples/batch_size, epochs=10)"],"metadata":{"id":"2YDKxTM4xeed"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#VGG 19"],"metadata":{"id":"iXifG03b3OhR"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import (\n","    Dense,\n","    Conv2D,\n","    MaxPool2D,\n","    Flatten,\n","    Dropout,\n","    BatchNormalization,\n",")\n","base_model = keras.applications.VGG19(\n","    weights='imagenet',\n","    input_shape=(128, 128, 3),\n","    include_top=False)\n","\n","base_model.summary()\n","base_model.trainable = False"],"metadata":{"id":"trcij1kr2SdF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inputs = keras.Input(shape=(128, 128, 3))\n","x = base_model(inputs, training=False)\n","x = keras.layers.GlobalAveragePooling2D()(x)\n","outputs = outputs = keras.layers.Dense(1)(x)\n","model = keras.Model(inputs, outputs)\n","model.summary()"],"metadata":{"id":"pkQRZa-n2faY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=True), metrics=[keras.metrics.BinaryAccuracy()])\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Create a data generator\n","datagen_train = ImageDataGenerator(\n","    samplewise_center=True,  # set each sample mean to 0\n","    rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n","    zoom_range=0.1,  # Randomly zoom image\n","    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n","    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n","    horizontal_flip=True,  # randomly flip images\n","    vertical_flip=False,\n","    validation_split=0.2\n",")\n","batch_size = 8\n","train_it = datagen_train.flow_from_directory(\n","    \"/content/drive/MyDrive/Kirmizi_Pistachio/Pistachio_Image_Dataset\",\n","    target_size=(128, 128),\n","    color_mode=\"rgb\",\n","    class_mode=\"binary\",\n","    batch_size=batch_size,\n","    subset='training'\n",")\n","valid_it = datagen_train.flow_from_directory(\n"," \"/content/drive/MyDrive/Kirmizi_Pistachio/Pistachio_Image_Dataset\",\n","    target_size=(128, 128),\n","    color_mode=\"rgb\",\n","    class_mode=\"binary\",\n","    batch_size=batch_size,\n","    subset='validation'\n",")\n","\n","model.fit(train_it, steps_per_epoch=train_it.samples/batch_size, validation_data=valid_it, validation_steps=valid_it.samples/batch_size, epochs=20)"],"metadata":{"id":"vZuPfH3g2lJ_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["base_model.trainable = True\n","\n","model.compile(optimizer=keras.optimizers.RMSprop(learning_rate = .00001),  # Very low learning rate\n","              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n","              metrics=[keras.metrics.BinaryAccuracy()])\n","\n","model.fit(train_it, steps_per_epoch=train_it.samples/batch_size, validation_data=valid_it, validation_steps=valid_it.samples/batch_size, epochs=10)"],"metadata":{"id":"JhvWKRUd2sGP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#AlexNet"],"metadata":{"id":"-G_44bzqK9Lm"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import (\n","    Conv2D,\n","    MaxPooling2D,\n","    Flatten,\n","    Dense,\n","    BatchNormalization,\n",")\n","def AlexNet(input_shape, num_classes):\n","    model = keras.Sequential([\n","        Conv2D(96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=input_shape),\n","        MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n","        Conv2D(256, kernel_size=(5,5), activation='relu', padding='same'),\n","        MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n","        Conv2D(384, kernel_size=(3,3), activation='relu', padding='same'),\n","        Conv2D(384, kernel_size=(3,3), activation='relu', padding='same'),\n","        Conv2D(256, kernel_size=(3,3), activation='relu', padding='same'),\n","        MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n","        Flatten(),\n","        Dense(4096, activation='relu'),\n","        Dense(4096, activation='relu'),\n","        Dense(num_classes, activation='softmax')\n","    ])\n","    return model\n","\n","    model.summery()\n","\n","# Load data\n","train_datagen = keras.preprocessing.image.ImageDataGenerator(\n","    rescale=1.0/255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    validation_split=0.2\n",")\n","\n","train_generator = train_datagen.flow_from_directory(\n","   \"/content/drive/MyDrive/Kirmizi_Pistachio/Pistachio_Image_Dataset\",\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='categorical',\n","    subset='training'\n",")\n","\n","validation_generator = train_datagen.flow_from_directory(\n","    \"/content/drive/MyDrive/Kirmizi_Pistachio/Pistachio_Image_Dataset\",\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='categorical',\n","    subset='validation'\n",")\n","\n","# Define model\n","input_shape = (224, 224, 3)\n","num_classes = 2  # Adjust this according to your dataset\n","alexnet_model = AlexNet(input_shape, num_classes)\n","\n","# Compile model\n","alexnet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train model\n","history = alexnet_model.fit(\n","    train_generator,\n","    steps_per_epoch=train_generator.samples // 32,\n","    validation_data=validation_generator,\n","    validation_steps=validation_generator.samples // 32,\n","    epochs=10\n",")\n","\n"],"metadata":{"id":"9OH9gpHe71dR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255)\n","\n","test_generator = test_datagen.flow_from_directory(\n","   \"/content/drive/MyDrive/Kirmizi_Pistachio/Pistachio_Image_Dataset\",\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='categorical'\n",")\n","\n","scores = alexnet_model.evaluate(test_generator)\n","print(\"Test Loss:\", scores[0])\n","print(\"Test Accuracy:\", scores[1])\n","\n","y_pred = alexnet_model.predict(test_generator)\n","y_true = test_generator.classes\n","confusion_mtx = tf.math.confusion_matrix(y_true, y_pred.argmax(axis=1))\n","print(\"Confusion Matrix:\")\n","print(confusion_mtx)\n"],"metadata":{"id":"bkKTqADsKXE7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import (\n","    Conv2D,\n","    MaxPooling2D,\n","    Flatten,\n","    Dense,\n","    BatchNormalization,\n",")\n","\n","def AlexNet(input_shape, num_classes):\n","    model = keras.Sequential([\n","        Conv2D(96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=input_shape),\n","        MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n","        Conv2D(256, kernel_size=(5,5), activation='relu', padding='same'),\n","        MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n","        Conv2D(384, kernel_size=(3,3), activation='relu', padding='same'),\n","        Conv2D(384, kernel_size=(3,3), activation='relu', padding='same'),\n","        Conv2D(256, kernel_size=(3,3), activation='relu', padding='same'),\n","        MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n","        Flatten(),\n","        Dense(4096, activation='relu'),\n","        Dense(4096, activation='relu'),\n","        Dense(num_classes, activation='softmax')\n","    ])\n","    return model\n","\n","# Load and preprocess data\n","train_datagen = keras.preprocessing.image.ImageDataGenerator(\n","    rescale=1.0/255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    validation_split=0.2\n",")\n","\n","train_generator = train_datagen.flow_from_directory(\n","   \"/content/drive/MyDrive/Kirmizi_Pistachio/Pistachio_Image_Dataset\",\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='categorical',\n","    subset='training'\n",")\n","\n","validation_generator = train_datagen.flow_from_directory(\n","    \"/content/drive/MyDrive/Kirmizi_Pistachio/Pistachio_Image_Dataset\",\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='categorical',\n","    subset='validation'\n",")\n","\n","# Define model\n","input_shape = (224, 224, 3)\n","num_classes = 2  # Adjust this according to your dataset\n","alexnet_model = AlexNet(input_shape, num_classes)\n","\n","# Compile model\n","alexnet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train model\n","history = alexnet_model.fit(\n","    train_generator,\n","    steps_per_epoch=train_generator.samples // 32,\n","    validation_data=validation_generator,\n","    validation_steps=validation_generator.samples // 32,\n","    epochs=10\n",")\n","model.fit(train_it, steps_per_epoch=train_it.samples/batch_size, validation_data=valid_it, validation_steps=valid_it.samples/batch_size, epochs=20)\n","# Evaluate model\n","test_generator = train_datagen.flow_from_directory(\n","   \"/content/drive/MyDrive/Kirmizi_Pistachio/Pistachio_Image_Dataset\",\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='categorical'\n",")\n","\n","scores = alexnet_model.evaluate(test_generator)\n","print(\"Test Loss:\", scores[0])\n","print(\"Test Accuracy:\", scores[1])\n","\n","# Generate predictions\n","y_pred = alexnet_model.predict(test_generator)\n","y_true = test_generator.classes\n","\n","# Calculate confusion matrix\n","confusion_mtx = tf.math.confusion_matrix(y_true, y_pred.argmax(axis=1))\n","print(\"Confusion Matrix:\")\n","print(confusion_mtx)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gfTfqO97sxA-","outputId":"d3dd69ec-49de-4cf9-b195-c9ea7b205186"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1719 images belonging to 2 classes.\n","Found 429 images belonging to 2 classes.\n","Epoch 1/10\n","49/53 [==========================>...] - ETA: 20s - loss: 1.1936 - accuracy: 0.5677"]}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1Tpmw_dRySxSE7gWlz7YsKjSeDqsHBA8e","authorship_tag":"ABX9TyOReeCx5WkcgJPZP4548/C8"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}